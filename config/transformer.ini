[model]
seed = 42
in_vocab = 5_000
out_vocab = 5_000
in_seq_len = 64
out_seq_len = 64
batch_size = 32
num_heads = 8
d_model = 256
d_ff = 1024
enc_layers = 3
dec_layers = 3

[training]
epochs = 10
lr = 0.001
data_path = ./data_splits/en_fr/train_tokenized.pickle
dataset_name = en_fr
batches_trained = 0
epochs_trained = 0

[validation]
data_path = ./data_splits/en_fr/val_tokenized.pickle

[wandb]
use_wandb = False
project = en_fr-transformer
notes = Initial run also will act as a baseline for future experiments
name = Initial run

[checkpoint]
use_checkpoint = False
checkpoint_path = ./checkpoint/en_fr/transformer/
checkpoint_freq = 25
