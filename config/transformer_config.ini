[model]
seed = 42
in_vocab = 5_000
out_vocab = 5_000
in_seq_len = 64
out_seq_len = 64
batch_size = 64
num_heads = 8
d_model = 256
enc_layers = 3
dec_layers = 3

[training]
epochs = 10
lr = 0.0001
data_path = ./data_splits/en_fr_train_tokenized.pickle
checkpoint_path = ./checkpoints/transfomer/
checkpoint_freq = 25
wandb = False
wandb_project = transformer
dataset = en_fr
wandb_notes = Initial run
