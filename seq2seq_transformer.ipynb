{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceaa3637",
   "metadata": {
    "id": "db414240",
    "raw_mimetype": "text/x-python"
   },
   "outputs": [],
   "source": [
    "import jax\n",
    "import optax\n",
    "import unicodedata\n",
    "import numpy as np\n",
    "import equinox as eqx\n",
    "import functools as ft\n",
    "import jax.numpy as jnp\n",
    "import sentencepiece as spm\n",
    "from jax import lax, config\n",
    "from itertools import islice, chain, repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1aafb617",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.update(\"jax_debug_nans\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "kzc35p6JEe18",
   "metadata": {
    "id": "kzc35p6JEe18"
   },
   "outputs": [],
   "source": [
    "def load_data(path: str):\n",
    "    \"\"\"\n",
    "    Load data from the given path of a file in utf-8 format.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    path: str\n",
    "        Path of the file to load.\n",
    "    \"\"\"\n",
    "    with open(path, encoding=\"utf-8\") as f:\n",
    "        return f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "lC2xxrPGH3y0",
   "metadata": {
    "id": "lC2xxrPGH3y0"
   },
   "outputs": [],
   "source": [
    "def train_spm(iterable, prefix, vocab=2_000, sentence_size=50_000, model_type=\"bpe\"):\n",
    "    \"\"\"\n",
    "    Train a sentence-piece tokenizer.\n",
    "    The pad, unk, bos, eos tokens corresponds to 0, 1, 3 and 4 id respectively.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    iterable: Sequence[str]\n",
    "        A list of sentences to train the toknizer.\n",
    "    prefix: str\n",
    "        A prefix for .model, .vocab files.\n",
    "    vocab: int, optional\n",
    "        Size of the vocabulary (default is 2_000)\n",
    "    sentence_size: int, optional\n",
    "        Size of sentences to sample for training. (default is 50_000)\n",
    "    model_type: str, optional\n",
    "        Type of model. Either \"bpe\" or \"unigram\". (default is \"bpe\")\n",
    "    \"\"\"\n",
    "    spm.SentencePieceTrainer.train(sentence_iterator=iter(iterable), model_prefix=prefix, vocab_size=vocab,\n",
    "                                   model_type=\"bpe\", normalization_rule_name=\"identity\", \n",
    "                                   input_sentence_size=sentence_size, shuffle_input_sentence=True, \n",
    "                                   pad_id=0, unk_id=1, bos_id=2, eos_id=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "SNPVoH1yI8Hd",
   "metadata": {
    "id": "SNPVoH1yI8Hd"
   },
   "outputs": [],
   "source": [
    "def load_spm(path):\n",
    "    \"\"\"\n",
    "    Load a pretrained tokenizer\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    path: str\n",
    "        Path to the model file\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    SentencePieceProcessor\n",
    "        A trained sentence-piece tokenizer.\n",
    "    \"\"\"\n",
    "    local_spm = spm.SentencePieceProcessor(model_file=path)\n",
    "    return local_spm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "zQv4-CQwPfNB",
   "metadata": {
    "id": "zQv4-CQwPfNB"
   },
   "outputs": [],
   "source": [
    "def normalize(arr, form):\n",
    "    \"\"\"\n",
    "    Performs unicode noramlization on sentences.\n",
    "\n",
    "    Paramters\n",
    "    ---------\n",
    "    arr: str\n",
    "        A list of sentences\n",
    "    form: str\n",
    "        Normalization form to use. NFD/NFC/NFKD/NFKC. (default is \"NFC\")\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        A list of normalized sentences.\n",
    "    \"\"\"\n",
    "    return [unicodedata.normalize(form, sentence.strip(\"\\n\")) for sentence in arr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "QhTLt3kLN1KH",
   "metadata": {
    "id": "QhTLt3kLN1KH"
   },
   "outputs": [],
   "source": [
    "def create_mask(arr):\n",
    "    \"\"\"\n",
    "    Creates a mask array in the same shape as the given a padded array.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    arr: jax.Array\n",
    "        Padded Array\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    jax.Array\n",
    "        A mask array.\n",
    "    \"\"\"\n",
    "    return jnp.where(arr == 0, np.NINF, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "vkrUJPwJP5Bo",
   "metadata": {
    "id": "vkrUJPwJP5Bo"
   },
   "outputs": [],
   "source": [
    "def data_split(arr, train_size=0.8, val_size=0.1):\n",
    "    \"\"\"\n",
    "    Splits a given list into train, validation and test sets. The sum of train &\n",
    "    validation sizes should not exceed 1. If the sum if < 1, test set has the remaining\n",
    "    elements of the array.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    arr: list\n",
    "        A list of sentences.\n",
    "    train_size: float, optional\n",
    "        Percentage of train set. (dafault is 0.8)\n",
    "    val_size: float, optional\n",
    "        Percentage of validation set (default is 0.1)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    (list, list, list)\n",
    "        A tuple of train, validation and test set.\n",
    "    \"\"\"\n",
    "    LEN = len(arr)\n",
    "    val_size = train_size + val_size\n",
    "    return arr[:int(LEN*train_size)], arr[int(LEN*train_size):int(LEN*val_size)], arr[int(LEN*val_size):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "qCUgSxL4NzZ1",
   "metadata": {
    "id": "qCUgSxL4NzZ1"
   },
   "outputs": [],
   "source": [
    "def pad_or_truncate(seq, size=32, pad=0):\n",
    "    \"\"\"\n",
    "    Pads and truncates a list tokens a specific length.\n",
    "\n",
    "    Parameters:\n",
    "    seq: list\n",
    "        A list of tokens.\n",
    "    size: int, optional\n",
    "        Max size of the sequence. (default is 32)\n",
    "    pad: int, optional\n",
    "        The ID to use for padding. (defualt is 0)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        Truncated or padded list of tokens.\n",
    "    \"\"\"\n",
    "    return list(islice(chain(seq, repeat(pad)), size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5292f993",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataloader(X, y, seq_len, batch_size=32):\n",
    "    \"\"\"\n",
    "    A dataloader for sequence to sequence tasks.\n",
    "    Loads data in batches.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X: list\n",
    "        Sequence of inputs.\n",
    "    y: list\n",
    "        Sequence of output.\n",
    "    seq_len: int\n",
    "        Max length of the sequence.\n",
    "    batch_size: int, optional\n",
    "        Size of a batch. (default is 32)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    generator[tuple]\n",
    "        Batches of X, y and labels\n",
    "    \"\"\"\n",
    "    if len(X) != len(y):\n",
    "        raise ValueError(\"Length of X and y are not equal\")\n",
    "    n = batch_size\n",
    "    X, y = iter(X), iter(y)\n",
    "    while batch := tuple(islice(zip(X, y), n)):\n",
    "        X_batched = [x[0] for x in batch]\n",
    "        y_batched = [x[1] for x in batch]\n",
    "        \n",
    "        X_batched = [pad_or_truncate(seq, seq_len) for seq in X_batched]\n",
    "        y_batched = [pad_or_truncate(seq, seq_len+1) for seq in y_batched]\n",
    "        ybt = [x[:-1] for x in y_batched]\n",
    "        labels = [x[1:] for x in y_batched]\n",
    "        \n",
    "        yield X_batched, ybt, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bff8d552",
   "metadata": {},
   "outputs": [],
   "source": [
    "en, fr = load_data(\"./en_fr/en\"), load_data(\"./en_fr/fr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5167ca4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "en, fr = normalize(en, \"NFC\"), normalize(fr, \"NFC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "84d6b798",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr, Xdev, Xte = data_split(en, train_size=0.7, val_size=0.15)\n",
    "ytr, ydev, yte = data_split(fr, train_size=0.7, val_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "vJMZgFKXJCT_",
   "metadata": {
    "id": "vJMZgFKXJCT_"
   },
   "outputs": [],
   "source": [
    "VOCAB = 5_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "024221a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_spm(Xtr, \"./tokenizer/en\", VOCAB, sentence_size=1_000_000)\n",
    "# train_spm(ytr, \"./tokenizer/fr\", VOCAB, sentence_size=1_000_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b45141f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_spm, fr_spm = load_spm(\"./tokenizer/en.model\"), load_spm(\"./tokenizer/fr.model\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "41b8ed37",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr, Xdev = [en_spm.tokenize(x, out_type=int) for x in (Xtr, Xdev)]\n",
    "ytr, ydev = [fr_spm.tokenize(x, out_type=int, add_bos=True, add_eos=True) for x in (ytr, ydev)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7ca6a3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "del en\n",
    "del fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4db58995",
   "metadata": {
    "id": "4db58995"
   },
   "outputs": [],
   "source": [
    "MODEL_DIM = EMB_SIZE = 256\n",
    "SEQ_LEN = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8a0c9bd6",
   "metadata": {
    "id": "8a0c9bd6"
   },
   "outputs": [],
   "source": [
    "class Linear(eqx.Module):\n",
    "    weights: jax.Array\n",
    "    bias: jax.Array\n",
    "    use_bias: bool = eqx.field(static=True)\n",
    "\n",
    "    def __init__(self, key, nin, nout, use_bias=False):\n",
    "        init = jax.nn.initializers.he_uniform()\n",
    "        self.weights = init(key=key, shape=(nin, nout))\n",
    "        if use_bias:\n",
    "            self.bias = jnp.ones(nout)\n",
    "        else: \n",
    "            self.bias = None\n",
    "        self.use_bias = use_bias\n",
    "        \n",
    "    @eqx.filter_jit\n",
    "    def __call__(self, x):\n",
    "        x = x @ self.weights\n",
    "        if self.use_bias:\n",
    "            x = x + self.bias\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "fe76caa0",
   "metadata": {
    "id": "fe76caa0"
   },
   "outputs": [],
   "source": [
    "class FFNN(eqx.Module):\n",
    "    layers: list\n",
    "    def __init__(self, key, nin, nout, nhidden, n_layers=2, use_bias=False):\n",
    "        keys = jax.random.split(key, num=n_layers)\n",
    "        layers = [\n",
    "            Linear(keys[0], nin, nhidden, use_bias)\n",
    "        ]\n",
    "        for i in range(1, n_layers-1):\n",
    "            layers.append(jax.nn.gelu)\n",
    "            layers.append(Linear(keys[i], nhidden, nhidden, use_bias))\n",
    "        if n_layers != 1:\n",
    "            layers.append(Linear(keys[-1], nhidden, nout, use_bias))\n",
    "        self.layers = layers\n",
    "\n",
    "    @eqx.filter_jit\n",
    "    def __call__(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "7cc4a6b0",
   "metadata": {
    "id": "7cc4a6b0"
   },
   "outputs": [],
   "source": [
    "class SelfAttention(eqx.Module):\n",
    "    @eqx.filter_jit\n",
    "    def __call__(self, query, key, value, mask):\n",
    "        scaled_dot_prod = query @ jnp.transpose(key, (0, 2, 1)) / jnp.sqrt(query.shape[-1])\n",
    "        scaled_dot_prod = mask + scaled_dot_prod\n",
    "        return (jax.nn.softmax(scaled_dot_prod) @ value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "6421e2be",
   "metadata": {
    "id": "6421e2be"
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttention(eqx.Module):\n",
    "    wquery: jax.Array\n",
    "    wkey: jax.Array\n",
    "    wvalue: jax.Array\n",
    "    weights: jax.Array\n",
    "    attn: eqx.Module\n",
    "    n_heads: int = eqx.field(static=True)\n",
    "    dim_k: int = eqx.field(static=True)\n",
    "\n",
    "    def __init__(self, key, n_heads, dim):\n",
    "        if (dim % n_heads) != 0:\n",
    "            raise ValueError(\"Model dimensions must be a multiple of no. of heads\")\n",
    "        dim_k = dim // n_heads\n",
    "        init = jax.nn.initializers.he_uniform()\n",
    "        wkey, qkey, kkey, vkey = jax.random.split(key, num=4)\n",
    "        self.weights = init(key=wkey, shape=(n_heads * dim_k, dim))\n",
    "        self.wquery = init(key=qkey, shape=(dim, dim))\n",
    "        self.wkey = init(key=kkey,shape=(dim, dim))\n",
    "        self.wvalue = init(key=vkey, shape=(dim, dim))\n",
    "        self.attn = SelfAttention()\n",
    "        self.n_heads = n_heads\n",
    "        self.dim_k = dim_k\n",
    "\n",
    "    @eqx.filter_jit\n",
    "    def __call__(self, query, key, value, mask):\n",
    "        query, key, value = query @ self.wquery, key @ self.wkey, value @ self.wvalue\n",
    "        query, key, value = [jnp.transpose(jnp.reshape(x, (-1, self.n_heads, self.dim_k)), (1, 0, 2)) for x in (query, key, value)]\n",
    "        mask = jnp.expand_dims(mask, axis=0)\n",
    "        attn = self.attn(query, key, value, mask)\n",
    "        return jnp.reshape(jnp.transpose(attn, (1, 0, 2)), (-1, self.n_heads * self.dim_k)) @ self.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "85d7ab91",
   "metadata": {
    "id": "85d7ab91"
   },
   "outputs": [],
   "source": [
    "class LayerNorm(eqx.Module):\n",
    "    gamma: jax.Array\n",
    "    bias: jax.Array\n",
    "    eps: int = eqx.field(static=True)\n",
    "\n",
    "    def __init__(self, size, eps=1e-6):\n",
    "        self.gamma = jnp.ones(size)\n",
    "        self.bias = jnp.ones(size)\n",
    "        self.eps = 1e-6\n",
    "\n",
    "    @eqx.filter_jit\n",
    "    def __call__(self, x):\n",
    "        mean = jnp.mean(x, -1, keepdims=True)\n",
    "        std = jnp.std(x, -1, keepdims=True)\n",
    "        return (self.gamma * (x - mean) / (std + self.eps)) + self.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b8cf8498",
   "metadata": {
    "id": "b8cf8498"
   },
   "outputs": [],
   "source": [
    "class Encoder(eqx.Module):\n",
    "    emb: jax.Array\n",
    "    attn_layers: list\n",
    "    ff_layers:list\n",
    "    attn_norms: list\n",
    "    ff_norms: list\n",
    "    n_layers: int = eqx.field(static=True)\n",
    "    pe: jax.Array = eqx.field(static=True)\n",
    "\n",
    "    def __init__(self, key, n_layers, n_heads, dim, seq_len, vocab):\n",
    "        keys = jax.random.split(key, num=n_layers*2+1)\n",
    "        emb_key, attn_keys, ff_keys = keys[0], keys[1:n_layers+1], keys[n_layers+1:]\n",
    "        self.emb = jax.random.normal(emb_key, (vocab, dim))\n",
    "        # Self-Attention & Forward Layers\n",
    "        self.attn_layers = [MultiHeadAttention(key, n_heads, dim) for key in attn_keys]\n",
    "        self.ff_layers = [FFNN(key, dim, dim, dim*2) for key in ff_keys]\n",
    "        # Layer Norms\n",
    "        self.attn_norms = [LayerNorm(dim) for _ in range(n_layers)]\n",
    "        self.ff_norms = [LayerNorm(dim) for _ in range(n_layers)]\n",
    "        # Positional Encodings\n",
    "        pos = jnp.arange(seq_len)[:, jnp.newaxis]\n",
    "        div_term = 10_000 ** (2 * jnp.arange(0, dim, 2) / dim)\n",
    "        pe = jnp.empty((seq_len, dim))\n",
    "        pe = pe.at[:, 0::2].set(jnp.sin(pos / div_term))\n",
    "        pe = pe.at[:, 1::2].set(jnp.cos(pos / div_term))\n",
    "        self.pe = pe\n",
    "        # Static Arguments\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "    @eqx.filter_jit\n",
    "    def __call__(self, x, mask):\n",
    "        x = self.emb[x[...]]\n",
    "        x = x + self.pe\n",
    "        for i in range(self.n_layers):\n",
    "            x = self.attn_norms[i](self.attn_layers[i](x, x, x, mask) + x)\n",
    "            x = self.ff_norms[i](self.ff_layers[i](x) + x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "b3c48c3b",
   "metadata": {
    "id": "b3c48c3b"
   },
   "outputs": [],
   "source": [
    "class Decoder(eqx.Module):\n",
    "    emb: jax.Array\n",
    "    mask: jax.Array = eqx.field(static=True)\n",
    "    masked_attn_layers: list\n",
    "    attn_layers: list\n",
    "    ff_layers:list\n",
    "    masked_attn_norms: list\n",
    "    attn_norms: list\n",
    "    ff_norms: list\n",
    "    n_layers: int = eqx.field(static=True)\n",
    "    pe: jax.Array = eqx.field(static=True)\n",
    "\n",
    "    def __init__(self, key, n_layers, n_heads, dim, seq_len, vocab):\n",
    "        keys = jax.random.split(key, num=n_layers*3+1)\n",
    "        emb_key, attn_keys, ff_keys, masked_attn_keys = keys[0], keys[1:n_layers+1], keys[n_layers+1:n_layers*2+1], keys[n_layers*2+1:]\n",
    "        self.emb = jax.random.normal(emb_key, (vocab, dim))\n",
    "        self.mask = jnp.where(jnp.triu(jnp.ones((seq_len, seq_len)), 1) == 1, np.NINF, 0)\n",
    "        # Masked-Attention, Self-Attention & Forward Layers\n",
    "        self.masked_attn_layers = [MultiHeadAttention(key, n_heads, dim) for key in masked_attn_keys]\n",
    "        self.attn_layers = [MultiHeadAttention(key, n_heads, dim) for key in attn_keys]\n",
    "        self.ff_layers = [FFNN(key, dim, dim, dim*2) for key in ff_keys]\n",
    "        # Layer Norms\n",
    "        self.masked_attn_norms = [LayerNorm(dim) for _ in range(n_layers)]\n",
    "        self.attn_norms = [LayerNorm(dim) for _ in range(n_layers)]\n",
    "        self.ff_norms = [LayerNorm(dim) for _ in range(n_layers)]\n",
    "        # Positional Encodings\n",
    "        pos = jnp.arange(seq_len)[:, jnp.newaxis]\n",
    "        div_term = 10_000 ** (2 * jnp.arange(0, dim, 2) / dim)\n",
    "        pe = jnp.empty((seq_len, dim))\n",
    "        pe = pe.at[:, 0::2].set(jnp.sin(pos / div_term))\n",
    "        pe = pe.at[:, 1::2].set(jnp.cos(pos / div_term))\n",
    "        self.pe = pe\n",
    "        # Static Arguments\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "    @eqx.filter_jit\n",
    "    def __call__(self, x, m, x_mask, m_mask):\n",
    "        x = self.emb[x[...]]\n",
    "        x = x + self.pe\n",
    "        x_mask = self.mask + x_mask\n",
    "        for i in range(self.n_layers):\n",
    "            x = self.masked_attn_norms[i](self.masked_attn_layers[i](x, x, x, x_mask) + x)\n",
    "            x = self.attn_norms[i](self.attn_layers[i](x, m, m, m_mask) + x)\n",
    "            x = self.ff_norms[i](self.ff_layers[i](x) + x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "fdf75eb5",
   "metadata": {
    "id": "fdf75eb5"
   },
   "outputs": [],
   "source": [
    "class EncoderDecoder(eqx.Module):\n",
    "    encoder: eqx.Module\n",
    "    decoder: eqx.Module\n",
    "\n",
    "    def __init__(self, key, dim, enc_heads, enc_layers, dec_heads, dec_layers, in_vocab, out_vocab, seq_len):\n",
    "        enc_key, dec_key = jax.random.split(key, num=2)\n",
    "        self.encoder = Encoder(enc_key, enc_layers, enc_heads, dim, seq_len, in_vocab)\n",
    "        self.decoder = Decoder(dec_key, dec_layers, dec_heads, dim, seq_len, out_vocab)\n",
    "\n",
    "    @eqx.filter_jit\n",
    "    def __call__(self, X, y, X_mask, y_mask):\n",
    "        m = self.encoder(X, X_mask)\n",
    "        h = self.decoder(y, m, y_mask, X_mask)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "da4da317",
   "metadata": {
    "id": "da4da317"
   },
   "outputs": [],
   "source": [
    "class Transformer(eqx.Module):\n",
    "    enc_dec: eqx.Module\n",
    "    linear: eqx.Module\n",
    "\n",
    "    def __init__(self, key, dim, enc_heads, enc_layers, dec_heads, dec_layers, in_vocab, out_vocab, seq_len):\n",
    "        encdec_key, linear_key = jax.random.split(key)\n",
    "        self.enc_dec = EncoderDecoder(encdec_key, dim,\n",
    "                                      enc_heads, enc_layers, \n",
    "                                      dec_heads, dec_layers, \n",
    "                                      in_vocab, out_vocab, seq_len)\n",
    "        self.linear = Linear(linear_key, dim, out_vocab)\n",
    "\n",
    "    @eqx.filter_jit\n",
    "    def __call__(self, X, y, X_mask, y_mask):\n",
    "        logits = self.enc_dec(X, y, X_mask, y_mask)\n",
    "        return jax.nn.softmax(self.linear(logits)) + 1e-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "9940839e",
   "metadata": {
    "id": "9940839e"
   },
   "outputs": [],
   "source": [
    "N_ENCODER_HEADS = N_DECODER_HEADS = 8\n",
    "N_ENCODER_LAYERS = N_DECODER_LAYERS = 3\n",
    "INPUT_VOCAB = OUTPUT_VOCAB = VOCAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "2428b19d",
   "metadata": {
    "id": "2428b19d"
   },
   "outputs": [],
   "source": [
    "key = jax.random.PRNGKey(0)\n",
    "model = Transformer(key, MODEL_DIM, \n",
    "                    N_ENCODER_HEADS, N_ENCODER_LAYERS, \n",
    "                    N_DECODER_HEADS, N_DECODER_LAYERS, \n",
    "                    INPUT_VOCAB, OUTPUT_VOCAB, SEQ_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "eo1qjbWXROeI",
   "metadata": {
    "id": "eo1qjbWXROeI"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32 \n",
    "EPOCHS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "3cP17zUixCc_",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3cP17zUixCc_",
    "outputId": "11a0fe63-4963-48d4-e4bc-36c82c698f02"
   },
   "outputs": [],
   "source": [
    "n_steps =  int(EPOCHS * len(Xtr)/BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "uvwdvhLUpiJK",
   "metadata": {
    "id": "uvwdvhLUpiJK"
   },
   "outputs": [],
   "source": [
    "scheduler = optax.warmup_cosine_decay_schedule(0.01, 10, n_steps//100, n_steps//10, 0.5)\n",
    "optimizer = optax.adam(learning_rate=scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "fu2Yv1QEqEuk",
   "metadata": {
    "id": "fu2Yv1QEqEuk"
   },
   "outputs": [],
   "source": [
    "def predict(model, X, y, X_mask, y_mask):\n",
    "    return model(X, y, X_mask, y_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "oB9BgzuepqVy",
   "metadata": {
    "id": "oB9BgzuepqVy"
   },
   "outputs": [],
   "source": [
    "def loss(model, X, y, X_mask, y_mask, labels):\n",
    "    y_pred = jnp.log(predict(model, X, y, X_mask, y_mask))\n",
    "    y_pred = jnp.where(labels==0, 0, jnp.take(y_pred, labels, axis=-1))\n",
    "    count = jnp.count_nonzero(y_pred)\n",
    "    return -jnp.sum(y_pred)/count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "41dc5a88",
   "metadata": {
    "id": "41dc5a88"
   },
   "outputs": [],
   "source": [
    "def optim(model, optimizer, loss_fn, vectorize=True, in_axes=None, out_axes=None):\n",
    "    opt_state = optimizer.init(model)\n",
    "    grad = jax.value_and_grad(loss_fn)\n",
    "    if vectorize:\n",
    "        gradient = jax.vmap(grad, in_axes=in_axes, out_axes=out_axes)\n",
    "\n",
    "    def step(model, opt_state, X, y, X_mask, y_mask, labels):\n",
    "        loss_value, grads = gradient(model, X, y, X_mask, y_mask, labels)\n",
    "        if vectorize:\n",
    "            loss_value = jnp.mean(loss_value)\n",
    "            grads = jax.tree_util.tree_map(lambda x: jnp.mean(x, axis=0), grads)\n",
    "        updates, opt_state = optimizer.update(grads, opt_state, model)\n",
    "        model = optax.apply_updates(model, updates)\n",
    "        return model, opt_state, loss_value\n",
    "\n",
    "    return opt_state, step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "c355e415",
   "metadata": {
    "id": "c355e415"
   },
   "outputs": [],
   "source": [
    "opt_state, step = optim(model, optimizer, loss, in_axes=(None, 0, 0, 0, 0, 0), out_axes=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "uqbtGzc-VaG9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uqbtGzc-VaG9",
    "outputId": "431559cf-3a92-4b12-95dc-d4a223c0c1cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batches trained: 20 | Avg. Batch loss: 14.472692489624023\n",
      "Batches trained: 40 | Avg. Batch loss: 14.5695161819458\n",
      "Batches trained: 60 | Avg. Batch loss: 15.60781192779541\n",
      "Batches trained: 80 | Avg. Batch loss: 16.869060516357422\n",
      "Batches trained: 100 | Avg. Batch loss: 17.63990020751953\n",
      "Batches trained: 120 | Avg. Batch loss: 18.153791427612305\n",
      "Batches trained: 140 | Avg. Batch loss: 18.520845413208008\n",
      "Batches trained: 160 | Avg. Batch loss: 18.796138763427734\n",
      "Batches trained: 180 | Avg. Batch loss: 19.0102596282959\n",
      "Batches trained: 200 | Avg. Batch loss: 19.181550979614258\n",
      "Invalid nan value encountered in the output of a C++-jit/pmap function. Calling the de-optimized version.\n"
     ]
    },
    {
     "ename": "FloatingPointError",
     "evalue": "invalid value (nan) encountered in jit(sub)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFloatingPointError\u001b[0m                        Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[1;32mD:\\Projects\\Data Science\\env\\lib\\site-packages\\jax\\_src\\dispatch.py:403\u001b[0m, in \u001b[0;36mcheck_special\u001b[1;34m(name, bufs)\u001b[0m\n\u001b[0;32m    402\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m buf \u001b[38;5;129;01min\u001b[39;00m bufs:\n\u001b[1;32m--> 403\u001b[0m   \u001b[43m_check_special\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Projects\\Data Science\\env\\lib\\site-packages\\jax\\_src\\dispatch.py:408\u001b[0m, in \u001b[0;36m_check_special\u001b[1;34m(name, dtype, buf)\u001b[0m\n\u001b[0;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mjax_debug_nans \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39many(np\u001b[38;5;241m.\u001b[39misnan(np\u001b[38;5;241m.\u001b[39masarray(buf))):\n\u001b[1;32m--> 408\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFloatingPointError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minvalid value (nan) encountered in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    409\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mjax_debug_infs \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39many(np\u001b[38;5;241m.\u001b[39misinf(np\u001b[38;5;241m.\u001b[39masarray(buf))):\n",
      "\u001b[1;31mFloatingPointError\u001b[0m: invalid value (nan) encountered in pjit",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFloatingPointError\u001b[0m                        Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[1;32mD:\\Projects\\Data Science\\env\\lib\\site-packages\\jax\\_src\\profiler.py:314\u001b[0m, in \u001b[0;36mannotate_function.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    313\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m TraceAnnotation(name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdecorator_kwargs):\n\u001b[1;32m--> 314\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapper\n",
      "File \u001b[1;32mD:\\Projects\\Data Science\\env\\lib\\site-packages\\jax\\_src\\interpreters\\pxla.py:1156\u001b[0m, in \u001b[0;36mExecuteReplicated.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1155\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m arrays \u001b[38;5;129;01min\u001b[39;00m out_arrays:\n\u001b[1;32m-> 1156\u001b[0m   \u001b[43mdispatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_special\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1157\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_handler(out_arrays)\n",
      "File \u001b[1;32mD:\\Projects\\Data Science\\env\\lib\\site-packages\\jax\\_src\\dispatch.py:403\u001b[0m, in \u001b[0;36mcheck_special\u001b[1;34m(name, bufs)\u001b[0m\n\u001b[0;32m    402\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m buf \u001b[38;5;129;01min\u001b[39;00m bufs:\n\u001b[1;32m--> 403\u001b[0m   \u001b[43m_check_special\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Projects\\Data Science\\env\\lib\\site-packages\\jax\\_src\\dispatch.py:408\u001b[0m, in \u001b[0;36m_check_special\u001b[1;34m(name, dtype, buf)\u001b[0m\n\u001b[0;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mjax_debug_nans \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39many(np\u001b[38;5;241m.\u001b[39misnan(np\u001b[38;5;241m.\u001b[39masarray(buf))):\n\u001b[1;32m--> 408\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFloatingPointError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minvalid value (nan) encountered in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    409\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mjax_debug_infs \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39many(np\u001b[38;5;241m.\u001b[39misinf(np\u001b[38;5;241m.\u001b[39masarray(buf))):\n",
      "\u001b[1;31mFloatingPointError\u001b[0m: invalid value (nan) encountered in jit(__call__)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFloatingPointError\u001b[0m                        Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[1;32mD:\\Projects\\Data Science\\env\\lib\\site-packages\\jax\\_src\\profiler.py:314\u001b[0m, in \u001b[0;36mannotate_function.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    313\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m TraceAnnotation(name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdecorator_kwargs):\n\u001b[1;32m--> 314\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapper\n",
      "File \u001b[1;32mD:\\Projects\\Data Science\\env\\lib\\site-packages\\jax\\_src\\interpreters\\pxla.py:1156\u001b[0m, in \u001b[0;36mExecuteReplicated.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1155\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m arrays \u001b[38;5;129;01min\u001b[39;00m out_arrays:\n\u001b[1;32m-> 1156\u001b[0m   \u001b[43mdispatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_special\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1157\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_handler(out_arrays)\n",
      "File \u001b[1;32mD:\\Projects\\Data Science\\env\\lib\\site-packages\\jax\\_src\\dispatch.py:403\u001b[0m, in \u001b[0;36mcheck_special\u001b[1;34m(name, bufs)\u001b[0m\n\u001b[0;32m    402\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m buf \u001b[38;5;129;01min\u001b[39;00m bufs:\n\u001b[1;32m--> 403\u001b[0m   \u001b[43m_check_special\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Projects\\Data Science\\env\\lib\\site-packages\\jax\\_src\\dispatch.py:408\u001b[0m, in \u001b[0;36m_check_special\u001b[1;34m(name, dtype, buf)\u001b[0m\n\u001b[0;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mjax_debug_nans \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39many(np\u001b[38;5;241m.\u001b[39misnan(np\u001b[38;5;241m.\u001b[39masarray(buf))):\n\u001b[1;32m--> 408\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFloatingPointError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minvalid value (nan) encountered in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    409\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mjax_debug_infs \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39many(np\u001b[38;5;241m.\u001b[39misinf(np\u001b[38;5;241m.\u001b[39masarray(buf))):\n",
      "\u001b[1;31mFloatingPointError\u001b[0m: invalid value (nan) encountered in jit(__call__)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFloatingPointError\u001b[0m                        Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[1;32mD:\\Projects\\Data Science\\env\\lib\\site-packages\\jax\\_src\\profiler.py:314\u001b[0m, in \u001b[0;36mannotate_function.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    313\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m TraceAnnotation(name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdecorator_kwargs):\n\u001b[1;32m--> 314\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapper\n",
      "File \u001b[1;32mD:\\Projects\\Data Science\\env\\lib\\site-packages\\jax\\_src\\interpreters\\pxla.py:1156\u001b[0m, in \u001b[0;36mExecuteReplicated.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1155\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m arrays \u001b[38;5;129;01min\u001b[39;00m out_arrays:\n\u001b[1;32m-> 1156\u001b[0m   \u001b[43mdispatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_special\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1157\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_handler(out_arrays)\n",
      "File \u001b[1;32mD:\\Projects\\Data Science\\env\\lib\\site-packages\\jax\\_src\\dispatch.py:403\u001b[0m, in \u001b[0;36mcheck_special\u001b[1;34m(name, bufs)\u001b[0m\n\u001b[0;32m    402\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m buf \u001b[38;5;129;01min\u001b[39;00m bufs:\n\u001b[1;32m--> 403\u001b[0m   \u001b[43m_check_special\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Projects\\Data Science\\env\\lib\\site-packages\\jax\\_src\\dispatch.py:408\u001b[0m, in \u001b[0;36m_check_special\u001b[1;34m(name, dtype, buf)\u001b[0m\n\u001b[0;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mjax_debug_nans \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39many(np\u001b[38;5;241m.\u001b[39misnan(np\u001b[38;5;241m.\u001b[39masarray(buf))):\n\u001b[1;32m--> 408\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFloatingPointError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minvalid value (nan) encountered in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    409\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mjax_debug_infs \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39many(np\u001b[38;5;241m.\u001b[39misinf(np\u001b[38;5;241m.\u001b[39masarray(buf))):\n",
      "\u001b[1;31mFloatingPointError\u001b[0m: invalid value (nan) encountered in jit(__call__)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFloatingPointError\u001b[0m                        Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[1;32mD:\\Projects\\Data Science\\env\\lib\\site-packages\\jax\\_src\\profiler.py:314\u001b[0m, in \u001b[0;36mannotate_function.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    313\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m TraceAnnotation(name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdecorator_kwargs):\n\u001b[1;32m--> 314\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapper\n",
      "File \u001b[1;32mD:\\Projects\\Data Science\\env\\lib\\site-packages\\jax\\_src\\interpreters\\pxla.py:1156\u001b[0m, in \u001b[0;36mExecuteReplicated.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1155\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m arrays \u001b[38;5;129;01min\u001b[39;00m out_arrays:\n\u001b[1;32m-> 1156\u001b[0m   \u001b[43mdispatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_special\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1157\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_handler(out_arrays)\n",
      "File \u001b[1;32mD:\\Projects\\Data Science\\env\\lib\\site-packages\\jax\\_src\\dispatch.py:403\u001b[0m, in \u001b[0;36mcheck_special\u001b[1;34m(name, bufs)\u001b[0m\n\u001b[0;32m    402\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m buf \u001b[38;5;129;01min\u001b[39;00m bufs:\n\u001b[1;32m--> 403\u001b[0m   \u001b[43m_check_special\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Projects\\Data Science\\env\\lib\\site-packages\\jax\\_src\\dispatch.py:408\u001b[0m, in \u001b[0;36m_check_special\u001b[1;34m(name, dtype, buf)\u001b[0m\n\u001b[0;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mjax_debug_nans \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39many(np\u001b[38;5;241m.\u001b[39misnan(np\u001b[38;5;241m.\u001b[39masarray(buf))):\n\u001b[1;32m--> 408\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFloatingPointError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minvalid value (nan) encountered in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    409\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mjax_debug_infs \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39many(np\u001b[38;5;241m.\u001b[39misinf(np\u001b[38;5;241m.\u001b[39masarray(buf))):\n",
      "\u001b[1;31mFloatingPointError\u001b[0m: invalid value (nan) encountered in jit(__call__)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFloatingPointError\u001b[0m                        Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[1;32mD:\\Projects\\Data Science\\env\\lib\\site-packages\\jax\\_src\\profiler.py:314\u001b[0m, in \u001b[0;36mannotate_function.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    313\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m TraceAnnotation(name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdecorator_kwargs):\n\u001b[1;32m--> 314\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapper\n",
      "File \u001b[1;32mD:\\Projects\\Data Science\\env\\lib\\site-packages\\jax\\_src\\interpreters\\pxla.py:1156\u001b[0m, in \u001b[0;36mExecuteReplicated.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1155\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m arrays \u001b[38;5;129;01min\u001b[39;00m out_arrays:\n\u001b[1;32m-> 1156\u001b[0m   \u001b[43mdispatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_special\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1157\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_handler(out_arrays)\n",
      "File \u001b[1;32mD:\\Projects\\Data Science\\env\\lib\\site-packages\\jax\\_src\\dispatch.py:403\u001b[0m, in \u001b[0;36mcheck_special\u001b[1;34m(name, bufs)\u001b[0m\n\u001b[0;32m    402\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m buf \u001b[38;5;129;01min\u001b[39;00m bufs:\n\u001b[1;32m--> 403\u001b[0m   \u001b[43m_check_special\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Projects\\Data Science\\env\\lib\\site-packages\\jax\\_src\\dispatch.py:408\u001b[0m, in \u001b[0;36m_check_special\u001b[1;34m(name, dtype, buf)\u001b[0m\n\u001b[0;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mjax_debug_nans \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39many(np\u001b[38;5;241m.\u001b[39misnan(np\u001b[38;5;241m.\u001b[39masarray(buf))):\n\u001b[1;32m--> 408\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFloatingPointError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minvalid value (nan) encountered in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    409\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mjax_debug_infs \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39many(np\u001b[38;5;241m.\u001b[39misinf(np\u001b[38;5;241m.\u001b[39masarray(buf))):\n",
      "\u001b[1;31mFloatingPointError\u001b[0m: invalid value (nan) encountered in jit(__call__)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mJaxStackTraceBeforeTransformation\u001b[0m         Traceback (most recent call last)",
      "File \u001b[1;32mD:\\Projects\\Data Science\\env\\lib\\runpy.py:196\u001b[0m, in \u001b[0;36m_run_module_as_main\u001b[1;34m()\u001b[0m\n\u001b[0;32m    195\u001b[0m     sys\u001b[38;5;241m.\u001b[39margv[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m mod_spec\u001b[38;5;241m.\u001b[39morigin\n\u001b[1;32m--> 196\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _run_code(code, main_globals, \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    197\u001b[0m                  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m, mod_spec)\n",
      "File \u001b[1;32mD:\\Projects\\Data Science\\env\\lib\\runpy.py:86\u001b[0m, in \u001b[0;36m_run_code\u001b[1;34m()\u001b[0m\n\u001b[0;32m     79\u001b[0m run_globals\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m=\u001b[39m mod_name,\n\u001b[0;32m     80\u001b[0m                    \u001b[38;5;18m__file__\u001b[39m \u001b[38;5;241m=\u001b[39m fname,\n\u001b[0;32m     81\u001b[0m                    __cached__ \u001b[38;5;241m=\u001b[39m cached,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     84\u001b[0m                    __package__ \u001b[38;5;241m=\u001b[39m pkg_name,\n\u001b[0;32m     85\u001b[0m                    __spec__ \u001b[38;5;241m=\u001b[39m mod_spec)\n\u001b[1;32m---> 86\u001b[0m exec(code, run_globals)\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m run_globals\n",
      "File \u001b[1;32mD:\\Projects\\Data Science\\env\\lib\\site-packages\\ipykernel_launcher.py:17\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mipykernel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m kernelapp \u001b[38;5;28;01mas\u001b[39;00m app\n\u001b[1;32m---> 17\u001b[0m app\u001b[38;5;241m.\u001b[39mlaunch_new_instance()\n",
      "File \u001b[1;32mD:\\Projects\\Data Science\\env\\lib\\site-packages\\traitlets\\config\\application.py:992\u001b[0m, in \u001b[0;36mlaunch_instance\u001b[1;34m()\u001b[0m\n\u001b[0;32m    991\u001b[0m app\u001b[38;5;241m.\u001b[39minitialize(argv)\n\u001b[1;32m--> 992\u001b[0m app\u001b[38;5;241m.\u001b[39mstart()\n",
      "File \u001b[1;32mD:\\Projects\\Data Science\\env\\lib\\site-packages\\ipykernel\\kernelapp.py:736\u001b[0m, in \u001b[0;36mstart\u001b[1;34m()\u001b[0m\n\u001b[0;32m    735\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 736\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mio_loop\u001b[38;5;241m.\u001b[39mstart()\n\u001b[0;32m    737\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n",
      "File \u001b[1;32mD:\\Projects\\Data Science\\env\\lib\\site-packages\\tornado\\platform\\asyncio.py:195\u001b[0m, in \u001b[0;36mstart\u001b[1;34m()\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstart\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 195\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39masyncio_loop\u001b[38;5;241m.\u001b[39mrun_forever()\n",
      "File \u001b[1;32mD:\\Projects\\Data Science\\env\\lib\\asyncio\\base_events.py:603\u001b[0m, in \u001b[0;36mrun_forever\u001b[1;34m()\u001b[0m\n\u001b[0;32m    602\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 603\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_once()\n\u001b[0;32m    604\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stopping:\n",
      "File \u001b[1;32mD:\\Projects\\Data Science\\env\\lib\\asyncio\\base_events.py:1909\u001b[0m, in \u001b[0;36m_run_once\u001b[1;34m()\u001b[0m\n\u001b[0;32m   1908\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1909\u001b[0m         handle\u001b[38;5;241m.\u001b[39m_run()\n\u001b[0;32m   1910\u001b[0m handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Projects\\Data Science\\env\\lib\\asyncio\\events.py:80\u001b[0m, in \u001b[0;36m_run\u001b[1;34m()\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 80\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_context\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_callback, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_args)\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mSystemExit\u001b[39;00m, \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m):\n",
      "File \u001b[1;32mD:\\Projects\\Data Science\\env\\lib\\site-packages\\ipykernel\\kernelbase.py:516\u001b[0m, in \u001b[0;36mdispatch_queue\u001b[1;34m()\u001b[0m\n\u001b[0;32m    515\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 516\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_one()\n\u001b[0;32m    517\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "File \u001b[1;32mD:\\Projects\\Data Science\\env\\lib\\site-packages\\ipykernel\\kernelbase.py:505\u001b[0m, in \u001b[0;36mprocess_one\u001b[1;34m()\u001b[0m\n\u001b[0;32m    504\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 505\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m dispatch(\u001b[38;5;241m*\u001b[39margs)\n",
      "File \u001b[1;32mD:\\Projects\\Data Science\\env\\lib\\site-packages\\ipykernel\\kernelbase.py:412\u001b[0m, in \u001b[0;36mdispatch_shell\u001b[1;34m()\u001b[0m\n\u001b[0;32m    411\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misawaitable(result):\n\u001b[1;32m--> 412\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m result\n\u001b[0;32m    413\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "File \u001b[1;32mD:\\Projects\\Data Science\\env\\lib\\site-packages\\ipykernel\\kernelbase.py:740\u001b[0m, in \u001b[0;36mexecute_request\u001b[1;34m()\u001b[0m\n\u001b[0;32m    739\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misawaitable(reply_content):\n\u001b[1;32m--> 740\u001b[0m     reply_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m reply_content\n\u001b[0;32m    742\u001b[0m \u001b[38;5;66;03m# Flush output before sending the reply.\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Projects\\Data Science\\env\\lib\\site-packages\\ipykernel\\ipkernel.py:422\u001b[0m, in \u001b[0;36mdo_execute\u001b[1;34m()\u001b[0m\n\u001b[0;32m    421\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m with_cell_id:\n\u001b[1;32m--> 422\u001b[0m     res \u001b[38;5;241m=\u001b[39m shell\u001b[38;5;241m.\u001b[39mrun_cell(\n\u001b[0;32m    423\u001b[0m         code,\n\u001b[0;32m    424\u001b[0m         store_history\u001b[38;5;241m=\u001b[39mstore_history,\n\u001b[0;32m    425\u001b[0m         silent\u001b[38;5;241m=\u001b[39msilent,\n\u001b[0;32m    426\u001b[0m         cell_id\u001b[38;5;241m=\u001b[39mcell_id,\n\u001b[0;32m    427\u001b[0m     )\n\u001b[0;32m    428\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mD:\\Projects\\Data Science\\env\\lib\\site-packages\\ipykernel\\zmqshell.py:546\u001b[0m, in \u001b[0;36mrun_cell\u001b[1;34m()\u001b[0m\n\u001b[0;32m    545\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_last_traceback \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 546\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrun_cell(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\Projects\\Data Science\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3024\u001b[0m, in \u001b[0;36mrun_cell\u001b[1;34m()\u001b[0m\n\u001b[0;32m   3023\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3024\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_cell(\n\u001b[0;32m   3025\u001b[0m         raw_cell, store_history, silent, shell_futures, cell_id\n\u001b[0;32m   3026\u001b[0m     )\n\u001b[0;32m   3027\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[1;32mD:\\Projects\\Data Science\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3079\u001b[0m, in \u001b[0;36m_run_cell\u001b[1;34m()\u001b[0m\n\u001b[0;32m   3078\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3079\u001b[0m     result \u001b[38;5;241m=\u001b[39m runner(coro)\n\u001b[0;32m   3080\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mD:\\Projects\\Data Science\\env\\lib\\site-packages\\IPython\\core\\async_helpers.py:129\u001b[0m, in \u001b[0;36m_pseudo_sync_runner\u001b[1;34m()\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 129\u001b[0m     coro\u001b[38;5;241m.\u001b[39msend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32mD:\\Projects\\Data Science\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3284\u001b[0m, in \u001b[0;36mrun_cell_async\u001b[1;34m()\u001b[0m\n\u001b[0;32m   3281\u001b[0m interactivity \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m silent \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mast_node_interactivity\n\u001b[1;32m-> 3284\u001b[0m has_raised \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_ast_nodes(code_ast\u001b[38;5;241m.\u001b[39mbody, cell_name,\n\u001b[0;32m   3285\u001b[0m        interactivity\u001b[38;5;241m=\u001b[39minteractivity, compiler\u001b[38;5;241m=\u001b[39mcompiler, result\u001b[38;5;241m=\u001b[39mresult)\n\u001b[0;32m   3287\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_execution_succeeded \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m has_raised\n",
      "File \u001b[1;32mD:\\Projects\\Data Science\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3466\u001b[0m, in \u001b[0;36mrun_ast_nodes\u001b[1;34m()\u001b[0m\n\u001b[0;32m   3465\u001b[0m     asy \u001b[38;5;241m=\u001b[39m compare(code)\n\u001b[1;32m-> 3466\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_code(code, result, async_\u001b[38;5;241m=\u001b[39masy):\n\u001b[0;32m   3467\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Projects\\Data Science\\env\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3526\u001b[0m, in \u001b[0;36mrun_code\u001b[1;34m()\u001b[0m\n\u001b[0;32m   3525\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 3526\u001b[0m         exec(code_obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_global_ns, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_ns)\n\u001b[0;32m   3527\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   3528\u001b[0m     \u001b[38;5;66;03m# Reset our crash handler in place\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[114], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m Xmask, ymask \u001b[38;5;241m=\u001b[39m [create_mask(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m (Xbt, ybt)]\n\u001b[1;32m---> 10\u001b[0m model, opt_state, batch_loss \u001b[38;5;241m=\u001b[39m step(model, opt_state, Xbt, ybt, Xmask, ymask, labelbt)\n\u001b[0;32m     11\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m batch_loss\n",
      "Cell \u001b[1;32mIn[112], line 8\u001b[0m, in \u001b[0;36mstep\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(model, opt_state, X, y, X_mask, y_mask, labels):\n\u001b[1;32m----> 8\u001b[0m     loss_value, grads \u001b[38;5;241m=\u001b[39m gradient(model, X, y, X_mask, y_mask, labels)\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m vectorize:\n",
      "Cell \u001b[1;32mIn[111], line 2\u001b[0m, in \u001b[0;36mloss\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mloss\u001b[39m(model, X, y, X_mask, y_mask, labels):\n\u001b[1;32m----> 2\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39mlog(predict(model, X, y, X_mask, y_mask))\n\u001b[0;32m      3\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39mwhere(labels\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, jnp\u001b[38;5;241m.\u001b[39mtake(y_pred, labels, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n",
      "Cell \u001b[1;32mIn[110], line 2\u001b[0m, in \u001b[0;36mpredict\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(model, X, y, X_mask, y_mask):\n\u001b[1;32m----> 2\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model(X, y, X_mask, y_mask)\n",
      "Cell \u001b[1;32mIn[104], line 15\u001b[0m, in \u001b[0;36m__call__\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;129m@eqx\u001b[39m\u001b[38;5;241m.\u001b[39mfilter_jit\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, X_mask, y_mask):\n\u001b[1;32m---> 15\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menc_dec(X, y, X_mask, y_mask)\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m jax\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39msoftmax(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear(logits)) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1e-9\u001b[39m\n",
      "Cell \u001b[1;32mIn[103], line 12\u001b[0m, in \u001b[0;36m__call__\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;129m@eqx\u001b[39m\u001b[38;5;241m.\u001b[39mfilter_jit\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, X_mask, y_mask):\n\u001b[1;32m---> 12\u001b[0m     m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(X, X_mask)\n\u001b[0;32m     13\u001b[0m     h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(y, m, y_mask, X_mask)\n",
      "Cell \u001b[1;32mIn[101], line 35\u001b[0m, in \u001b[0;36m__call__\u001b[1;34m()\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_layers):\n\u001b[1;32m---> 35\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattn_norms[i](\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattn_layers[i](x, x, x, mask) \u001b[38;5;241m+\u001b[39m x)\n\u001b[0;32m     36\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mff_norms[i](\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mff_layers[i](x) \u001b[38;5;241m+\u001b[39m x)\n",
      "Cell \u001b[1;32mIn[99], line 29\u001b[0m, in \u001b[0;36m__call__\u001b[1;34m()\u001b[0m\n\u001b[0;32m     28\u001b[0m mask \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39mexpand_dims(mask, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m---> 29\u001b[0m attn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattn(query, key, value, mask)\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m jnp\u001b[38;5;241m.\u001b[39mreshape(jnp\u001b[38;5;241m.\u001b[39mtranspose(attn, (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m)), (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_heads \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdim_k)) \u001b[38;5;241m@\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights\n",
      "Cell \u001b[1;32mIn[98], line 6\u001b[0m, in \u001b[0;36m__call__\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m scaled_dot_prod \u001b[38;5;241m=\u001b[39m mask \u001b[38;5;241m+\u001b[39m scaled_dot_prod\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (jax\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39msoftmax(scaled_dot_prod) \u001b[38;5;241m@\u001b[39m value)\n",
      "File \u001b[1;32mD:\\Projects\\Data Science\\env\\lib\\site-packages\\jax\\_src\\nn\\functions.py:455\u001b[0m, in \u001b[0;36msoftmax\u001b[1;34m()\u001b[0m\n\u001b[0;32m    454\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 455\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _softmax_deprecated(x, axis, where, initial)\n",
      "File \u001b[1;32mD:\\Projects\\Data Science\\env\\lib\\site-packages\\jax\\_src\\nn\\functions.py:483\u001b[0m, in \u001b[0;36m_softmax_deprecated\u001b[1;34m()\u001b[0m\n\u001b[0;32m    482\u001b[0m x_max \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39mmax(x, axis, where\u001b[38;5;241m=\u001b[39mwhere, initial\u001b[38;5;241m=\u001b[39minitial, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 483\u001b[0m unnormalized \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39mexp(x \u001b[38;5;241m-\u001b[39m lax\u001b[38;5;241m.\u001b[39mstop_gradient(x_max))\n\u001b[0;32m    484\u001b[0m result \u001b[38;5;241m=\u001b[39m unnormalized \u001b[38;5;241m/\u001b[39m jnp\u001b[38;5;241m.\u001b[39msum(unnormalized, axis, where\u001b[38;5;241m=\u001b[39mwhere, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mD:\\Projects\\Data Science\\env\\lib\\site-packages\\jax\\_src\\numpy\\array_methods.py:728\u001b[0m, in \u001b[0;36mop\u001b[1;34m()\u001b[0m\n\u001b[0;32m    727\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mop\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m--> 728\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maval, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs)\n",
      "File \u001b[1;32mD:\\Projects\\Data Science\\env\\lib\\site-packages\\jax\\_src\\numpy\\array_methods.py:256\u001b[0m, in \u001b[0;36mdeferring_binary_op\u001b[1;34m()\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other, _accepted_binop_types):\n\u001b[1;32m--> 256\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m binary_op(\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m    257\u001b[0m \u001b[38;5;66;03m# Note: don't use isinstance here, because we don't want to raise for\u001b[39;00m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;66;03m# subclasses, e.g. NamedTuple objects that may override operators.\u001b[39;00m\n",
      "\u001b[1;31mJaxStackTraceBeforeTransformation\u001b[0m: FloatingPointError: invalid value (nan) encountered in jit(sub)\n\nThe preceding stack trace is the source of the JAX operation that, once transformed by JAX, triggered the following exception.\n\n--------------------",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mFloatingPointError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[114], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m Xbt, ybt, labelbt \u001b[38;5;241m=\u001b[39m [jnp\u001b[38;5;241m.\u001b[39marray(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m (Xbt, ybt, labelbt)]\n\u001b[0;32m      8\u001b[0m Xmask, ymask \u001b[38;5;241m=\u001b[39m [create_mask(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m (Xbt, ybt)]\n\u001b[1;32m---> 10\u001b[0m model, opt_state, batch_loss \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mXbt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mybt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mXmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mymask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabelbt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m batch_loss\n\u001b[0;32m     12\u001b[0m num_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "Cell \u001b[1;32mIn[112], line 8\u001b[0m, in \u001b[0;36moptim.<locals>.step\u001b[1;34m(model, opt_state, X, y, X_mask, y_mask, labels)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(model, opt_state, X, y, X_mask, y_mask, labels):\n\u001b[1;32m----> 8\u001b[0m     loss_value, grads \u001b[38;5;241m=\u001b[39m \u001b[43mgradient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m vectorize:\n\u001b[0;32m     10\u001b[0m         loss_value \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39mmean(loss_value)\n",
      "    \u001b[1;31m[... skipping hidden 11 frame]\u001b[0m\n",
      "Cell \u001b[1;32mIn[111], line 2\u001b[0m, in \u001b[0;36mloss\u001b[1;34m(model, X, y, X_mask, y_mask, labels)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mloss\u001b[39m(model, X, y, X_mask, y_mask, labels):\n\u001b[1;32m----> 2\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39mlog(\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_mask\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m      3\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39mwhere(labels\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, jnp\u001b[38;5;241m.\u001b[39mtake(y_pred, labels, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m      4\u001b[0m     count \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39mcount_nonzero(y_pred)\n",
      "Cell \u001b[1;32mIn[110], line 2\u001b[0m, in \u001b[0;36mpredict\u001b[1;34m(model, X, y, X_mask, y_mask)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(model, X, y, X_mask, y_mask):\n\u001b[1;32m----> 2\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_mask\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[1;31m[... skipping hidden 40 frame]\u001b[0m\n",
      "    \u001b[1;31m[... skipping similar frames: _pjit_call_impl_python at line 1156 (2 times), _pjit_call_impl.<locals>.call_impl_cache_miss at line 1196 (2 times), eval_jaxpr at line 454 (2 times), jaxpr_as_fun at line 235 (2 times), _pjit_call_impl at line 1212 (1 times), AxisPrimitive.bind at line 2657 (1 times), Primitive.bind_with_trace at line 389 (1 times), EvalTrace.process_primitive at line 869 (1 times)]\u001b[0m\n",
      "    \u001b[1;31m[... skipping hidden 17 frame]\u001b[0m\n",
      "File \u001b[1;32mD:\\Projects\\Data Science\\env\\lib\\site-packages\\jax\\_src\\dispatch.py:408\u001b[0m, in \u001b[0;36m_check_special\u001b[1;34m(name, dtype, buf)\u001b[0m\n\u001b[0;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtypes\u001b[38;5;241m.\u001b[39missubdtype(dtype, np\u001b[38;5;241m.\u001b[39minexact):\n\u001b[0;32m    407\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mjax_debug_nans \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39many(np\u001b[38;5;241m.\u001b[39misnan(np\u001b[38;5;241m.\u001b[39masarray(buf))):\n\u001b[1;32m--> 408\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFloatingPointError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minvalid value (nan) encountered in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    409\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mjax_debug_infs \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39many(np\u001b[38;5;241m.\u001b[39misinf(np\u001b[38;5;241m.\u001b[39masarray(buf))):\n\u001b[0;32m    410\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFloatingPointError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minvalid value (inf) encountered in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mFloatingPointError\u001b[0m: invalid value (nan) encountered in jit(sub)"
     ]
    }
   ],
   "source": [
    "for e in range(EPOCHS):\n",
    "    total_loss = 0\n",
    "    num_batches = 0\n",
    "    total_tokens = 0\n",
    "    for i, (Xbt, ybt, labelbt) in enumerate(dataloader(Xtr, ytr, SEQ_LEN)):\n",
    "        total_tokens += len([token for seq in labelbt for token in list(filter(lambda x: x!=0, seq))])\n",
    "        Xbt, ybt, labelbt = [jnp.array(x) for x in (Xbt, ybt, labelbt)]\n",
    "        Xmask, ymask = [create_mask(x) for x in (Xbt, ybt)]\n",
    "\n",
    "        model, opt_state, batch_loss = step(model, opt_state, Xbt, ybt, Xmask, ymask, labelbt)\n",
    "        total_loss += batch_loss\n",
    "        num_batches += 1\n",
    "\n",
    "        if num_batches % 20 == 0:\n",
    "            print(f\"Batches trained: {num_batches} | Avg. Batch loss: {total_loss/num_batches}\")\n",
    "\n",
    "    epoch_loss = total_loss / num_batches\n",
    "    print(f\"Epoch {e} | loss: {epoch_loss}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "celltoolbar": "Raw Cell Format",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
